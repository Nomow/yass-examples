#!/usr/bin/env python
"""
Memory profiling for the pipeline, looks for a config.yaml file in the
same folder.

See this for usage:

https://github.com/pythonprofilers/memory_profiler

Run with:

mprof run pipeline.py
"""
import logging
import argparse
from memory_profiler import profile
import yass
from yass import preprocess, detect, cluster, templates, deconvolute


@profile
def main():
    """Profiling memory in YASS pipeline
    """
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("config", type=str,
                        help="Path to config file, defaults to "
                             "'./config.yaml'", default='config.yaml')
    parser.add_argument("-l", "--logger", type=str, help="Logger level",
                        default="INFO")
    args = parser.parse_args()

    logging.basicConfig(level=getattr(logging, args.logger))
    yass.set_config(args.config)

    # configure logging module to get useful information
    logging.basicConfig(level=logging.DEBUG)

    # set yass configuration parameters
    yass.set_config('config.yaml')

    # preprocessing
    (standarized_path, standarized_params, channel_index,
     whiten_filter) = preprocess.run()

    # detection
    (score, spike_index_clear,
     spike_index_all) = detect.run(standarized_path,
                                   standarized_params,
                                   channel_index,
                                   whiten_filter)

    # clustering
    spike_train_clear = cluster.run(score, spike_index_clear)

    # templates
    the_templates = templates.run(spike_train_clear)

    # deconvolution
    deconvolute.run(spike_index_all, the_templates)


if __name__ == '__main__':
    main()
