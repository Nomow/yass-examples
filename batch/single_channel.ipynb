{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Edu/miniconda3/envs/yass/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Splitting large file into batches where every batch contains n\n",
    "observations from 1 channel\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from yass.batch import BatchProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_neuropixel_data = (os.path.expanduser('~/data/ucl-neuropixel'\n",
    "                           '/rawDataSample.bin'))\n",
    "\n",
    "\n",
    "bp = BatchProcessor(path_to_neuropixel_data,\n",
    "                    dtype='int16', n_channels=385, data_format='wide',\n",
    "                    max_memory='1MB')\n",
    "\n",
    "# there are two ways of traversing the data: single_channel and multi_channel\n",
    "# single_channel means that the data in a single batch comes from only one\n",
    "# channel, multi_channel means that a batch can contain data from multiple\n",
    "# channels, let's take a look at single_channel operations\n",
    "\n",
    "# traverse the whole dataset, one channel at a time\n",
    "data = bp.single_channel()\n",
    "\n",
    "# the next for loop will raise an error since we cannot fit all observations for a single\n",
    "# channel in memory, so we either increase max_memory or set\n",
    "# force_complete_channel_batch to False\n",
    "\n",
    "# for d in data:\n",
    "#     print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524288,) Data from channel 0\n",
      "(524288,) Data from channel 0\n",
      "(524288,) Data from channel 0\n",
      "(227136,) Data from channel 0\n",
      "(524288,) Data from channel 1\n",
      "(524288,) Data from channel 1\n",
      "(524288,) Data from channel 1\n",
      "(227136,) Data from channel 1\n",
      "(524288,) Data from channel 2\n",
      "(524288,) Data from channel 2\n",
      "(524288,) Data from channel 2\n",
      "(227136,) Data from channel 2\n"
     ]
    }
   ],
   "source": [
    "# When force_complete_channel_batch is False, each batch does not necessarily\n",
    "# correspond to all observations in the channel, the channel can be splitted\n",
    "# in several batches (although every batch data is guaranteed to come from\n",
    "# a single channel), in this case, every channel is splitted in two parts\n",
    "data = bp.single_channel(force_complete_channel_batch=False, channels=[0, 1, 2])\n",
    "\n",
    "for d, ch in data:\n",
    "    print(d.shape, 'Data from channel {}'.format(ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "# finally, we can traverse a single channel in a temporal subset\n",
    "data = bp.single_channel(from_time=100000, to_time=200000, channels=[0, 1, 2])\n",
    "\n",
    "for d in data:\n",
    "    print(d.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
