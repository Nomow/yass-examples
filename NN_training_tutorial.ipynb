{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Load yass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yass\n",
    "from yass import read_config\n",
    "from yass.augment import make_training_data, save_detect_network_params, save_triage_network_params, save_ae_network_params\n",
    "from yass.neuralnetwork import train_detector, train_ae, train_triage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Read Configuration File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yass.set_config(\"location/to/config.yaml\")\n",
    "CONFIG = read_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Load Spike Train**\n",
    "\n",
    "To train the Neural Network, you need to have a recording with sorted result. The result does not need to be perfect.\n",
    "If you don't have any sorting result yet, you can run yass with threshold detection option. In your configuration file, set spikes.detection = threshold.\n",
    "\n",
    "spike_train is a matrix of size (number of spikes x 2). Each row represents an individual spike. The first column is the spike time (not in milliseconds or seconds but in actual temporal location in recording). The second column is the spike ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is an example. Load your spike_train using your own way\n",
    "import numpy as np\n",
    "spike_train = np.loadtxt('path/to/csv/file.csv', dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Make Training Dataset**\n",
    "\n",
    "1. CONFIG and spike_train are from step 2 and 3.\n",
    "\n",
    "2. chosen_templates: It is a vector containing which templates to use. Given spike sorting result, not all templates look good. Therefore, the training dataset should be obtained from good looking templates only. Make sure that you do not include bad templates. However, it is still important to keep variability in template shapes. To visually check templates, check optional step at the bottom.\n",
    "\n",
    "3. min_amp: the minimum of absolute maximal amplitude of augmented spikes. It should determine how small spikes in the training set can be. Default is 3.\n",
    "\n",
    "4. nspikes: approximately how many training data it should produce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_amp = 5\n",
    "nspikes = 50000\n",
    "chosen_templates = [0, 1, 2, 3, 5, 10] # should be your own number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_detect, y_detect, x_triage, y_triage, x_ae, y_ae = make_training_data(CONFIG, spike_train, chosen_templates, min_amp, nspikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Train All Three Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters:\n",
    "1. n_iter: the number of iterations to run\n",
    "2. n_batch: the size of mini-batch to be used for training\n",
    "3. l2_reg_scale: L2 regularization penalty term\n",
    "4. train_step_size: training step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter = 5000\n",
    "n_batch = 512\n",
    "l2_reg_scale = 0.00000005\n",
    "train_step_size =  0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training neural net detector\n",
    "1. detectnet_name: name of saved model with the location to save \n",
    "2. n_filters: number of filters to use in each layer. It should be a list of length 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detectnet_name = '/location/you/want/test_detect_nn.ckpt'\n",
    "n_filters_detect = [16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "train_detector(x_detect, y_detect, n_filters_detect, n_iter, n_batch, l2_reg_scale, train_step_size, detectnet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "save_detect_network_params(filters = n_filters_detect,\n",
    "                           size = x_detect.shape[1],\n",
    "                           n_neighbors = x_detect.shape[2],\n",
    "                           output_path = detectnet_name.replace('ckpt', 'yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training neural net triage\n",
    "1. triagenet_name: name of saved model with the location to save \n",
    "2. n_filters: number of filters to use in each layer. It should be a list of length 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triagenet_name = '/location/you/want/test_triage_nn.ckpt'\n",
    "n_filters_triage = [16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "train_triage(x_triage, y_triage, n_filters_triage, n_iter, n_batch, l2_reg_scale, train_step_size, triagenet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "save_triage_network_params(filters = n_filters_triage,\n",
    "                           size = x_detect.shape[1],\n",
    "                           n_neighbors = x_detect.shape[2],\n",
    "                           output_path = triagenet_name.replace('ckpt', 'yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training autoencoder\n",
    "1. ae_name: name of saved model with the location to save \n",
    "2. n_feature: number of latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_name = '/location/you/want/test_ae_nn.ckpt'\n",
    "n_features = 3\n",
    "n_batch = x_ae.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "train_ae(x_ae, y_ae, n_features, n_iter, n_batch, train_step_size, ae_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "save_ae_network_params(n_input = x_ae.shape[1],\n",
    "                       n_features = n_features,\n",
    "                       output_path = ae_name.replace('ckpt', 'yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You are done!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: When Using yass**\n",
    "\n",
    "Make sure that you have all your files! You must have **3 '.ckpt'** files and **1 '.yaml'** file for **each neural network model**, which make **total 12 files**.\n",
    "\n",
    "Also, make sure that the parameters in your configuration file match with the parameters used during the training\n",
    "\n",
    "| Name in config.yaml | How it should change |\n",
    "|---|---|\n",
    "|spikes.temporal_features|n_feature used for training autoencoder|\n",
    "|recordings.spike_size_ms|make sure that this value stays the same as configuration loaded here|\n",
    "|neural_network_detector.filename|file name used above to save neural net detector|\n",
    "|neural_network_triage.filename|file name used above to save neural net triage|\n",
    "|neural_network_autoencoder.filename|file name used above to save neural net autoencoder|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.2: Visually Inspect Templates (optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from yass.augment.templates import get_templates\n",
    "from yass.augment.process import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data to get standardized recording\n",
    "process_data(CONFIG)\n",
    "\n",
    "# prameters\n",
    "path = os.path.join(CONFIG.data.root_folder,  'tmp/standarized.bin')\n",
    "dtype = 'float64'\n",
    "\n",
    "# make templates\n",
    "templates = get_templates(spike_train, CONFIG.batch_size, \n",
    "                          CONFIG.BUFF, CONFIG.nBatches, \n",
    "                          CONFIG.recordings.n_channels, \n",
    "                          CONFIG.spikeSize*2, \n",
    "                          path, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(templates.shape[2]):\n",
    "    plt.plot(templates[:,:,k].T)\n",
    "    plt.title(str(k))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
